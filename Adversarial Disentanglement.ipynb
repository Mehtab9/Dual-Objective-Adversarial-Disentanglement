{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46f1f19-7bfa-481b-8999-bce82f159054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import IPython.display as ipd\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import math\n",
    "import re\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from torch.autograd import Function\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import shutil\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from scipy import signal\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd9a93-b28f-45bd-8577-0b0052fa67da",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f39b7-8bbe-49b0-a2c2-11ade6a956f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SPLIT_DIR = \"./data/CV_FOLDS/\"\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "def load_audio_data_with_labels(csv_path, sample_rate=16000):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    audio_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        file_path = row['audio_path']\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "            audio_data.append({\n",
    "                \"audio\": torch.tensor(audio, dtype=torch.float32),  \n",
    "                \"speaker_id\": row['speaker_id'],\n",
    "                \"status\": 1 if row['status'] == 'pd' else 0,  \n",
    "                \"sex\": 1 if row['SEX'] == 'M' else 0,        \n",
    "                \"file_name\": file_path\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "def preprocess_audio_with_labels(signals, gender_labels, health_labels, sample_rate, file_names=None):\n",
    "    selected_segments = []\n",
    "    segment_gender_labels = []\n",
    "    segment_health_labels = []\n",
    "    segment_file_names = []\n",
    "    skipped_quiet = 0\n",
    "\n",
    "    for audio, gender_label, health_label, file_name in zip(signals, gender_labels, health_labels, file_names):\n",
    "\n",
    "        max_amp = torch.max(torch.abs(audio))\n",
    "        if max_amp < 1e-6:  # Skip near-silent audio\n",
    "            skipped_quiet += 1\n",
    "            print(f\"Skipping near silent audio: {file_name}\")\n",
    "            continue\n",
    "        audio = audio / max_amp  \n",
    "\n",
    "        selected_segments.append(audio)\n",
    "        segment_gender_labels.append(gender_label)\n",
    "        segment_health_labels.append(health_label)\n",
    "        segment_file_names.append(file_name)\n",
    "\n",
    "    return selected_segments, segment_gender_labels, segment_health_labels, segment_file_names\n",
    "\n",
    "\n",
    "\n",
    "all_folds_X_train = []\n",
    "all_folds_yg_train = []\n",
    "all_folds_yh_train = []\n",
    "all_folds_filenames_train = []\n",
    "\n",
    "all_folds_X_test = []\n",
    "all_folds_yg_test = []\n",
    "all_folds_yh_test = []\n",
    "all_folds_filenames_test = []\n",
    "\n",
    "\n",
    "all_folds_X_val = []\n",
    "all_folds_yg_val = []\n",
    "all_folds_yh_val = []\n",
    "all_folds_filenames_val = []\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(1, 11):\n",
    "    fold_dir = os.path.join(SPLIT_DIR, f\"FOLD_{fold}\")\n",
    "    train_path = os.path.join(fold_dir, \"train.csv\")\n",
    "    val_path = os.path.join(fold_dir, \"val.csv\")  \n",
    "    test_path = os.path.join(fold_dir, \"test.csv\")\n",
    "    \n",
    "    train_data = load_audio_data_with_labels(train_path, SAMPLE_RATE)\n",
    "    train_signals = [item[\"audio\"] for item in train_data]\n",
    "    train_gender_labels = [item[\"sex\"] for item in train_data]\n",
    "    train_health_labels = [item[\"status\"] for item in train_data]\n",
    "    train_file_names = [item[\"file_name\"] for item in train_data]\n",
    "    \n",
    "    X_train_processed, yg_train, yh_train, filenames_train = preprocess_audio_with_labels(\n",
    "        train_signals, train_gender_labels, train_health_labels, SAMPLE_RATE, file_names=train_file_names\n",
    "    )\n",
    "    \n",
    "    all_folds_X_train.append(X_train_processed)\n",
    "    all_folds_yg_train.append(yg_train)\n",
    "    all_folds_yh_train.append(yh_train)\n",
    "    all_folds_filenames_train.append(filenames_train)\n",
    "    \n",
    "    print(f\"Fold {fold} - Processed {len(X_train_processed)} audio segments for training.\")\n",
    "    \n",
    "    val_data = load_audio_data_with_labels(val_path, SAMPLE_RATE)\n",
    "    val_signals = [item[\"audio\"] for item in val_data]\n",
    "    val_gender_labels = [item[\"sex\"] for item in val_data]\n",
    "    val_health_labels = [item[\"status\"] for item in val_data]\n",
    "    val_file_names = [item[\"file_name\"] for item in val_data]\n",
    "    \n",
    "    X_val_processed, yg_val, yh_val, filenames_val = preprocess_audio_with_labels(\n",
    "        val_signals, val_gender_labels, val_health_labels, SAMPLE_RATE, file_names=val_file_names\n",
    "    )\n",
    "    \n",
    "    all_folds_X_val.append(X_val_processed)\n",
    "    all_folds_yg_val.append(yg_val)\n",
    "    all_folds_yh_val.append(yh_val)\n",
    "    all_folds_filenames_val.append(filenames_val)\n",
    "\n",
    "    print(f\"Fold {fold} - Processed {len(X_val_processed)} audio segments for validation.\")\n",
    "    \n",
    "    test_data = load_audio_data_with_labels(test_path, SAMPLE_RATE)\n",
    "    test_signals = [item[\"audio\"] for item in test_data]\n",
    "    test_gender_labels = [item[\"sex\"] for item in test_data]\n",
    "    test_health_labels = [item[\"status\"] for item in test_data]\n",
    "    test_file_names = [item[\"file_name\"] for item in test_data]\n",
    "    \n",
    "    X_test_processed, yg_test, yh_test, filenames_test = preprocess_audio_with_labels(\n",
    "        test_signals, test_gender_labels, test_health_labels, SAMPLE_RATE, file_names=test_file_names\n",
    "    )\n",
    "    \n",
    "    all_folds_X_test.append(X_test_processed)\n",
    "    all_folds_yg_test.append(yg_test)\n",
    "    all_folds_yh_test.append(yh_test)\n",
    "    all_folds_filenames_test.append(filenames_test)\n",
    "    \n",
    "    print(f\"Fold {fold} - Processed {len(X_test_processed)} audio segments for testing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c51431-d9f1-43a4-9e21-4e87819f27ba",
   "metadata": {},
   "source": [
    "# X vector extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f4eaf-3d02-4b3c-845f-97b833a1bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from speechbrain.inference.speaker import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", \n",
    "                                            savedir=\"pretrained_models/spkrec-xvect-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5a376-78f2-4baf-acff-ea43de6e646c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def X_vector(signals):\n",
    "    x_vector = []\n",
    "    \n",
    "    for i, audio in enumerate(signals):\n",
    "        if audio.ndim == 1:\n",
    "            audio = audio.unsqueeze(0)\n",
    "\n",
    "        embeddings = classifier.encode_batch(audio)\n",
    "        embedding_shape = embeddings.shape\n",
    "        squeezed_embedding = embeddings.squeeze(dim=0).squeeze(dim=0)\n",
    "        if squeezed_embedding.shape[0] != 512:\n",
    "            print(f\"Warning: Unexpected embedding size for sample {i} after squeezing with shape {squeezed_embedding.shape}\")\n",
    "\n",
    "        x_vector.append(squeezed_embedding.detach().cpu().numpy())\n",
    "\n",
    "    x_vector = np.stack(x_vector, axis=0)\n",
    "    return x_vector\n",
    "\n",
    "\n",
    "def standardize_data(train_xvectors, val_xvectors, test_xvectors):\n",
    "    \n",
    "    mu = np.mean(train_xvectors, axis=0)\n",
    "    std_dev = np.std(train_xvectors, axis=0)\n",
    "\n",
    "    std_dev[std_dev == 0] = 1e-6\n",
    "    \n",
    "    standardized_train = (train_xvectors - mu) / std_dev\n",
    "    standardized_val   = (val_xvectors - mu) / std_dev\n",
    "    standardized_test  = (test_xvectors - mu) / std_dev\n",
    "\n",
    "    return standardized_train, standardized_val, standardized_test\n",
    "    \n",
    "\n",
    "all_folds_train_xvectors = []\n",
    "all_folds_val_xvectors = []\n",
    "all_folds_test_xvectors = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for fold in range(10):\n",
    "        print(f\"\\nProcessing Fold {fold + 1}\")\n",
    "\n",
    "        X_train_processed = all_folds_X_train[fold]\n",
    "        X_val_processed   = all_folds_X_val[fold]\n",
    "        X_test_processed  = all_folds_X_test[fold]\n",
    "\n",
    "    \n",
    "        X_train_xvectors = X_vector(X_train_processed)\n",
    "        X_val_xvectors   = X_vector(X_val_processed)\n",
    "        X_test_xvectors  = X_vector(X_test_processed)\n",
    "\n",
    "        print(f\"Fold {fold + 1} - Before standardization:\")\n",
    "        print(f\"  Train X-Vectors shape: {X_train_xvectors.shape}\")\n",
    "        print(f\"  Val X-Vectors shape:   {X_val_xvectors.shape}\")\n",
    "        print(f\"  Test X-Vectors shape:  {X_test_xvectors.shape}\")\n",
    "\n",
    "        X_train_xvectors, X_val_xvectors, X_test_xvectors = standardize_data(\n",
    "            X_train_xvectors, X_val_xvectors, X_test_xvectors\n",
    "        )\n",
    "\n",
    "        print(f\"Fold {fold + 1} - After standardization:\")\n",
    "        print(f\"  Train X-Vectors shape: {X_train_xvectors.shape}\")\n",
    "        print(f\"  Val X-Vectors shape:   {X_val_xvectors.shape}\")\n",
    "        print(f\"  Test X-Vectors shape:  {X_test_xvectors.shape}\")\n",
    "\n",
    "        all_folds_train_xvectors.append(X_train_xvectors)\n",
    "        all_folds_val_xvectors.append(X_val_xvectors)\n",
    "        all_folds_test_xvectors.append(X_test_xvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea91b50-b5e6-4757-ae30-46ad85241f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class XVectorDataset(Dataset):\n",
    "    def __init__(self, x_vectors, gender_labels, health_labels, filenames):\n",
    "        # Ensure all data is converted to appropriate tensor formats\n",
    "        self.x_vectors = torch.tensor(x_vectors, dtype=torch.float32) if not isinstance(x_vectors, torch.Tensor) else x_vectors\n",
    "        self.gender_labels = torch.tensor(gender_labels, dtype=torch.int64) if not isinstance(gender_labels, torch.Tensor) else gender_labels\n",
    "        self.health_labels = torch.tensor(health_labels, dtype=torch.int64) if not isinstance(health_labels, torch.Tensor) else health_labels\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_vectors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_vector = self.x_vectors[idx]\n",
    "        gender_label = self.gender_labels[idx]\n",
    "        health_label = self.health_labels[idx]\n",
    "        filename = self.filenames[idx]\n",
    "\n",
    "        return x_vector, gender_label, health_label, filename\n",
    "\n",
    "\n",
    "def create_data_loader(x_vectors, gender_labels, health_labels, filenames, batch_size, shuffle=False):\n",
    "    dataset = XVectorDataset(x_vectors, gender_labels, health_labels, filenames)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "# BATCH_SIZE = 4\n",
    "\n",
    "# # Loop through folds\n",
    "# for fold in range(10):\n",
    "#     print(f\"\\nCreating DataLoaders for Fold {fold + 1}\")\n",
    "\n",
    "#     # --- TRAIN ---\n",
    "#     X_train_xvectors = all_folds_train_xvectors[fold]\n",
    "#     yg_train = all_folds_yg_train[fold]\n",
    "#     yh_train = all_folds_yh_train[fold]\n",
    "#     filenames_train = all_folds_filenames_train[fold]\n",
    "\n",
    "#     train_loader = create_data_loader(\n",
    "#         X_train_xvectors, yg_train, yh_train, filenames_train, BATCH_SIZE, shuffle=True\n",
    "#     )\n",
    "\n",
    "#     # --- VALIDATION (NEW) ---\n",
    "#     X_val_xvectors = all_folds_val_xvectors[fold]\n",
    "#     yg_val = all_folds_yg_val[fold]\n",
    "#     yh_val = all_folds_yh_val[fold]\n",
    "#     filenames_val = all_folds_filenames_val[fold]\n",
    "\n",
    "#     val_loader = create_data_loader(\n",
    "#         X_val_xvectors, yg_val, yh_val, filenames_val, BATCH_SIZE, shuffle=False\n",
    "#     )\n",
    "\n",
    "#     # --- TEST ---\n",
    "#     X_test_xvectors = all_folds_test_xvectors[fold]\n",
    "#     yg_test = all_folds_yg_test[fold]\n",
    "#     yh_test = all_folds_yh_test[fold]\n",
    "#     filenames_test = all_folds_filenames_test[fold]\n",
    "\n",
    "#     test_loader = create_data_loader(\n",
    "#         X_test_xvectors, yg_test, yh_test, filenames_test, BATCH_SIZE, shuffle=False\n",
    "#     )\n",
    "\n",
    "#     print(f\"Train DataLoader for Fold {fold + 1} has {len(train_loader)} batches.\")\n",
    "#     print(f\"Val DataLoader   for Fold {fold + 1} has {len(val_loader)} batches.\")\n",
    "#     print(f\"Test DataLoader  for Fold {fold + 1} has {len(test_loader)} batches.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6592e52-2a83-4cf3-a7a5-7e3fd9c40406",
   "metadata": {},
   "source": [
    "# gender classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ffa8aa6-82dc-47cc-97bc-e3c12074cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "class GenderClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GenderClassifier, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_dim, output_dim)\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.sigm(self.linear1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# class GenderClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim):\n",
    "#         super(GenderClassifier, self).__init__()\n",
    "#         self.linear1 = nn.Linear(input_dim, 128)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(128, output_dim)\n",
    "#         self.sigm = nn.Sigmoid()  \n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.linear1(x))\n",
    "#         x = self.sigm(self.linear2(x))\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bb7cf-324e-407d-aea1-7247a4e33add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# input_dim = 512  \n",
    "# output_dim = 1  \n",
    "# num_epochs = 20\n",
    "# BATCH_SIZE = 4\n",
    "# learning_rate = 0.0001\n",
    "# patience = 5              \n",
    "\n",
    "\n",
    "# all_fold_train_losses = []\n",
    "# all_fold_val_losses = []       \n",
    "# all_fold_val_roc_aucs = []      \n",
    "# all_fold_roc_auc_scores = []    \n",
    "\n",
    "# all_fold_best_val_aucs = []\n",
    "\n",
    "\n",
    "# all_true_labels = []\n",
    "# all_predictions = []\n",
    "\n",
    "\n",
    "\n",
    "# for fold in range(5):\n",
    "#     print(f\"\\nStarting fold {fold + 1}/5\")\n",
    "    \n",
    "   \n",
    "#     train_loader = create_data_loader(\n",
    "#         all_folds_train_xvectors[fold], all_folds_yg_train[fold], all_folds_yh_train[fold],\n",
    "#         all_folds_filenames_train[fold], BATCH_SIZE, shuffle=True\n",
    "#     )\n",
    "\n",
    "#     val_loader = create_data_loader(\n",
    "#         all_folds_val_xvectors[fold],\n",
    "#         all_folds_yg_val[fold],\n",
    "#         all_folds_yh_val[fold],\n",
    "#         all_folds_filenames_val[fold],\n",
    "#         BATCH_SIZE, shuffle=False\n",
    "#     )\n",
    "\n",
    "    \n",
    "#     test_loader = create_data_loader(\n",
    "#         all_folds_test_xvectors[fold], all_folds_yg_test[fold], all_folds_yh_test[fold],\n",
    "#         all_folds_filenames_test[fold], BATCH_SIZE, shuffle=False\n",
    "#     )\n",
    "\n",
    "    \n",
    "#     model = GenderClassifier(input_dim, output_dim).to(device)\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "   \n",
    "#     fold_train_losses = []\n",
    "#     fold_val_losses = []\n",
    "#     fold_val_aucs = []\n",
    "\n",
    "    \n",
    "#     best_val_auc = 0.0\n",
    "#     best_model_weights = None\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "\n",
    "#         for x_vectors, gender_labels, _, _ in train_loader:\n",
    "#             x_vectors = x_vectors.to(device)\n",
    "#             gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(x_vectors)\n",
    "#             loss = criterion(outputs, gender_labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "\n",
    "        \n",
    "#         train_loss = running_loss / len(train_loader)\n",
    "#         fold_train_losses.append(train_loss)\n",
    "\n",
    "\n",
    "#         model.eval()\n",
    "#         val_running_loss = 0.0\n",
    "#         val_true_labels = []\n",
    "#         val_predictions = []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for x_vectors, gender_labels, _, _ in val_loader:\n",
    "#                 x_vectors = x_vectors.to(device)\n",
    "#                 gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "#                 outputs = model(x_vectors)\n",
    "\n",
    "#                 val_loss = criterion(outputs, gender_labels)\n",
    "#                 val_running_loss += val_loss.item()\n",
    "\n",
    "#                 val_predictions.extend(outputs.cpu().numpy())\n",
    "#                 val_true_labels.extend(gender_labels.cpu().numpy())\n",
    "\n",
    "#         val_loss_epoch = val_running_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "#         val_roc_auc = roc_auc_score(val_true_labels, val_predictions)\n",
    "        \n",
    "#         fold_val_losses.append(val_loss_epoch)\n",
    "#         fold_val_aucs.append(val_roc_auc)\n",
    "\n",
    "\n",
    "#         if val_roc_auc > best_val_auc:\n",
    "#             best_val_auc = val_roc_auc\n",
    "#             best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "#         print(f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs}, \"\n",
    "#               f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss_epoch:.4f}, Val ROC: {val_roc_auc:.4f}\")        \n",
    "\n",
    "#     all_fold_train_losses.append(fold_train_losses)\n",
    "#     all_fold_val_losses.append(fold_val_losses)\n",
    "#     all_fold_val_roc_aucs.append(fold_val_aucs)\n",
    "#     all_fold_best_val_aucs.append(best_val_auc)\n",
    "\n",
    "#     final_model_path = f\"model_gender2layers_fold_{fold+1}_finalNVZ.pth\"\n",
    "#     torch.save(model.state_dict(), final_model_path)\n",
    "#     print(f\"Saved FINAL model for Fold {fold+1} as '{final_model_path}'\")  \n",
    "\n",
    "#     if best_model_weights is not None:\n",
    "#         best_model_path = f\"model_gender2layers_fold_{fold+1}_bestValNVZ.pth\"\n",
    "#         torch.save(best_model_weights, best_model_path)\n",
    "#         print(f\"Saved BEST-VAL model for Fold {fold+1} (AUC={best_val_auc:.4f}) as '{best_model_path}'\")\n",
    "\n",
    "    \n",
    "    \n",
    "#     # model.load_state_dict(best_model_weights)    \n",
    "#     model.eval()\n",
    "#     true_labels, predictions = [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for x_vectors, gender_labels, _, _ in test_loader:\n",
    "#             x_vectors = x_vectors.to(device)\n",
    "#             gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "#             outputs = model(x_vectors)\n",
    "\n",
    "#             predictions.extend(outputs.cpu().numpy())\n",
    "#             true_labels.extend(gender_labels.cpu().numpy())\n",
    "\n",
    "            \n",
    "#     all_true_labels.extend(true_labels)\n",
    "#     all_predictions.extend(predictions)  \n",
    "   \n",
    "#     roc_auc = roc_auc_score(true_labels, predictions)\n",
    "#     all_fold_roc_auc_scores.append(roc_auc)\n",
    "#     print(f\"Fold {fold + 1}, Test ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "#     fpr, tpr, _ = roc_curve(true_labels, predictions)\n",
    "#     plt.figure()\n",
    "#     plt.plot(fpr, tpr, label=f'Fold {fold + 1} ROC curve (area = {roc_auc:.4f})')\n",
    "#     plt.plot([0, 1], [0, 1], 'k--')  \n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title(f'ROC Curve for Fold {fold + 1}')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# avg_roc_auc = np.mean(all_fold_roc_auc_scores)\n",
    "# std_roc_auc = np.std(all_fold_roc_auc_scores)\n",
    "# print(f\"\\nAverage Test ROC AUC across folds: {avg_roc_auc:.4f} ± {std_roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "# avg_best_val_auc = np.mean(all_fold_best_val_aucs)\n",
    "# std_best_val_auc = np.std(all_fold_best_val_aucs)\n",
    "# print(f\"Average BEST Val AUC Across Folds: {avg_best_val_auc:.4f} ± {std_best_val_auc:.4f}\")\n",
    "\n",
    "\n",
    "# # plt.figure(figsize=(10, 5))\n",
    "# # for fold_idx, (train_losses, val_losses) in enumerate(zip(all_fold_train_losses, all_fold_val_losses), 1):\n",
    "# #     plt.plot(range(1, num_epochs + 1), train_losses, label=f'Fold {fold_idx} - Train')\n",
    "# #     plt.plot(range(1, num_epochs + 1), val_losses, label=f'Fold {fold_idx} - Val')\n",
    "# # plt.xlabel('Epoch')\n",
    "# # plt.ylabel('Loss')\n",
    "# # plt.title('Training & Validation Loss Curves for Each Fold')\n",
    "# # plt.legend()\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# all_true_labels = np.array(all_true_labels).flatten()\n",
    "# all_predictions = np.array(all_predictions).flatten()\n",
    "\n",
    "# male_scores = all_predictions[all_true_labels == 1]\n",
    "# female_scores = all_predictions[all_true_labels == 0]\n",
    "\n",
    "# plt.figure(figsize=(4, 4))\n",
    "# plt.hist(female_scores, bins=100, alpha=0.9, color='blue', label='Female')\n",
    "# plt.hist(male_scores, bins=100, alpha=0.9, color='red', label='Male')\n",
    "# plt.xlabel('Predicted Probability')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Posterior Probabilities Across All Folds')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1802fd-af67-4399-bad2-c40dbc4448bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0001, 0.00001],\n",
    "    'batch_size': [4],\n",
    "    'optimizer': ['adam', 'sgd']\n",
    "   \n",
    "}\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "all_fold_train_losses = []\n",
    "all_fold_val_losses = []\n",
    "all_fold_val_aucs = []\n",
    "all_fold_test_aucs = []\n",
    "all_fold_best_val_aucs = []\n",
    "all_fold_best_params = []\n",
    "\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting fold {fold+1}/10\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    best_fold_auc = 0.0\n",
    "    best_fold_params = None\n",
    "    best_model_weights_for_fold = None  \n",
    "\n",
    "  \n",
    "    for (lr, bs, opt_name) in param_combinations:\n",
    "        print(f\"\\n  Searching - (LR={lr}, BatchSize={bs}, Optim={opt_name})\")\n",
    "\n",
    "        train_loader = create_data_loader(\n",
    "            all_folds_train_xvectors[fold],\n",
    "            all_folds_yg_train[fold],\n",
    "            all_folds_yh_train[fold],\n",
    "            all_folds_filenames_train[fold],\n",
    "            batch_size=bs, shuffle=True\n",
    "        )\n",
    "        val_loader = create_data_loader(\n",
    "            all_folds_val_xvectors[fold],\n",
    "            all_folds_yg_val[fold],\n",
    "            all_folds_yh_val[fold],\n",
    "            all_folds_filenames_val[fold],\n",
    "            batch_size=bs, shuffle=False\n",
    "        )\n",
    "\n",
    "      \n",
    "        model = GenderClassifier(input_dim, output_dim).to(device)  \n",
    "        criterion = nn.BCELoss()\n",
    "        if opt_name == 'adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "        \n",
    "        best_val_auc_for_combo = 0.0\n",
    "        best_model_weights_for_combo = None\n",
    "\n",
    "       \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for x_vectors, gender_labels, health_labels, _ in train_loader:\n",
    "                x_vectors = x_vectors.to(device)\n",
    "                gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_vectors)\n",
    "                loss = criterion(outputs, gender_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_preds = []\n",
    "            val_true = []\n",
    "            with torch.no_grad():\n",
    "                for x_vectors, gender_labels, health_labels, _ in val_loader:\n",
    "                    x_vectors = x_vectors.to(device)\n",
    "                    gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "                    outputs = model(x_vectors)\n",
    "                    val_preds.extend(outputs.cpu().numpy())\n",
    "                    val_true.extend(gender_labels.cpu().numpy())\n",
    "\n",
    "            val_auc = roc_auc_score(val_true, val_preds)\n",
    "\n",
    "           \n",
    "            if val_auc > best_val_auc_for_combo:\n",
    "                best_val_auc_for_combo = val_auc\n",
    "                best_model_weights_for_combo = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if best_val_auc_for_combo > best_fold_auc:\n",
    "            best_fold_auc = best_val_auc_for_combo\n",
    "            best_fold_params = (lr, bs, opt_name)\n",
    "            best_model_weights_for_fold = best_model_weights_for_combo\n",
    "\n",
    "    print(f\"\\nBest hyperparameters for fold {fold+1}:\")\n",
    "    print(f\"   LR={best_fold_params[0]}, BatchSize={best_fold_params[1]}, Optim={best_fold_params[2]}\")\n",
    "    print(f\"   Best Val AUC from grid search = {best_fold_auc:.4f}\")\n",
    "\n",
    "    all_fold_best_params.append(best_fold_params)\n",
    "\n",
    "   \n",
    "    final_bs = best_fold_params[1]\n",
    "    final_train_loader = create_data_loader(\n",
    "        all_folds_train_xvectors[fold],\n",
    "        all_folds_yg_train[fold],\n",
    "        all_folds_yh_train[fold],\n",
    "        all_folds_filenames_train[fold],\n",
    "        batch_size=final_bs, shuffle=True\n",
    "    )\n",
    "    final_val_loader = create_data_loader(\n",
    "        all_folds_val_xvectors[fold],\n",
    "        all_folds_yg_val[fold],\n",
    "        all_folds_yh_val[fold],\n",
    "        all_folds_filenames_val[fold],\n",
    "        batch_size=final_bs, shuffle=False\n",
    "    )\n",
    "    test_loader = create_data_loader(\n",
    "        all_folds_test_xvectors[fold],\n",
    "        all_folds_yg_test[fold],\n",
    "        all_folds_yh_test[fold],\n",
    "        all_folds_filenames_test[fold],\n",
    "        batch_size=final_bs, shuffle=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    model = GenderClassifier(input_dim, output_dim).to(device)\n",
    "\n",
    "    .\n",
    "    if best_fold_params[2] == 'adam':\n",
    "        optimizer_h = optim.Adam(model.parameters(), lr=best_fold_params[0]) \n",
    "    else:\n",
    "        optimizer_h = optim.SGD(model.parameters(), lr=best_fold_params[0], momentum=0.9)\n",
    "\n",
    "    criterion_h = nn.BCELoss()\n",
    "\n",
    "    \n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_aucs = []\n",
    "\n",
    "    best_val_auc_this_fold = 0.0\n",
    "    best_model_weights_this_fold = None\n",
    "    epochs_without_improvement = 0  \n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for x_vectors, gender_labels, health_labels, _ in final_train_loader:\n",
    "            x_vectors = x_vectors.to(device)\n",
    "            gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "            optimizer_h.zero_grad()\n",
    "            outputs = model(x_vectors)\n",
    "            loss = criterion_h(outputs, gender_labels)\n",
    "            loss.backward()\n",
    "            optimizer_h.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "     \n",
    "        train_loss = running_loss / len(final_train_loader)\n",
    "        fold_train_losses.append(train_loss)\n",
    "\n",
    "       \n",
    "        model.eval()\n",
    "        val_loss_accum = 0.0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_vectors, gender_labels, health_labels, _ in final_val_loader:\n",
    "                x_vectors = x_vectors.to(device)\n",
    "                gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "                outputs = model(x_vectors)\n",
    "                val_loss = criterion_h(outputs, gender_labels)\n",
    "                val_loss_accum += val_loss.item()\n",
    "\n",
    "                val_preds.extend(outputs.cpu().numpy())\n",
    "                val_true.extend(gender_labels.cpu().numpy())\n",
    "\n",
    "        val_loss_avg = val_loss_accum / len(final_val_loader)\n",
    "        val_auc = roc_auc_score(val_true, val_preds)\n",
    "\n",
    "        fold_val_losses.append(val_loss_avg)\n",
    "        fold_val_aucs.append(val_auc)\n",
    "\n",
    "        \n",
    "        if val_auc > best_val_auc_this_fold:\n",
    "            best_val_auc_this_fold = val_auc\n",
    "            best_model_weights_this_fold = copy.deepcopy(model.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"  [Early Stopping] No improvement for {patience} epochs. Stopping at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss_avg:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    \n",
    "    final_model_path = f\"model_gender_fold_{fold+1}_finalNVZ.pth\"\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Saved FINAL model for Fold {fold+1} as '{final_model_path}'\")\n",
    "\n",
    "    \n",
    "    if best_model_weights_this_fold is not None:\n",
    "        best_model_path = f\"model_gender_fold_{fold+1}_bestValNVZ.pth\"\n",
    "        torch.save(best_model_weights_this_fold, best_model_path)\n",
    "        print(f\"Saved BEST-VAL model for Fold {fold+1} (AUC={best_val_auc_this_fold:.4f}) as '{best_model_path}'\")\n",
    "    else:\n",
    "        print(\"No improvement was tracked, best_model_weights_this_fold is None (check logic).\")\n",
    "\n",
    "    \n",
    "    if best_model_weights_this_fold is not None:\n",
    "        model.load_state_dict(best_model_weights_this_fold)\n",
    "\n",
    "    model.eval()\n",
    "    test_true, test_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_vectors, gender_labels, health_labels, _ in test_loader:\n",
    "            x_vectors = x_vectors.to(device)\n",
    "            gender_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "            outputs = model(x_vectors)\n",
    "\n",
    "            test_preds.extend(outputs.cpu().numpy())\n",
    "            test_true.extend(gender_labels.cpu().numpy())\n",
    "\n",
    "    labels.extend(test_true)\n",
    "    predictions.extend(test_preds)    \n",
    "\n",
    "    test_auc = roc_auc_score(test_true, test_preds)\n",
    "    all_fold_test_aucs.append(test_auc)\n",
    "    print(f\"\\nFold {fold+1}, Test ROC AUC: {test_auc:.4f}\")\n",
    "\n",
    "   \n",
    "    fpr, tpr, _ = roc_curve(test_true, test_preds)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'Fold {fold+1} (AUC={test_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f' Test ROC - Fold {fold+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    all_fold_train_losses.append(fold_train_losses)\n",
    "    all_fold_val_losses.append(fold_val_losses)\n",
    "    all_fold_val_aucs.append(fold_val_aucs)\n",
    "    all_fold_best_val_aucs.append(best_val_auc_this_fold)\n",
    "\n",
    "avg_test_auc = np.mean(all_fold_test_aucs)\n",
    "std_test_auc = np.std(all_fold_test_aucs, ddof=1)\n",
    "print(f\"\\nAverage Test ROC AUC: {avg_test_auc:.4f} ± {std_test_auc:.4f}\")\n",
    "\n",
    "avg_best_val_auc = np.mean(all_fold_best_val_aucs)\n",
    "std_best_val_auc = np.std(all_fold_best_val_aucs, ddof=1)\n",
    "print(f\"Average BEST Val AUC Across Folds: {avg_best_val_auc:.4f} ± {std_best_val_auc:.4f}\")\n",
    "\n",
    "print(\"\\nBest Parameters per Fold:\")\n",
    "for fold_idx, params in enumerate(all_fold_best_params):\n",
    "    print(f\"  Fold {fold_idx+1}: LR={params[0]}, BS={params[1]}, Optim={params[2]}\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# for fold_idx, (train_losses, val_losses) in enumerate(zip(all_fold_train_losses, all_fold_val_losses), 1):\n",
    "#     # Each fold might have a different number of epochs if early stopping triggered\n",
    "#     epochs_range = range(1, len(train_losses) + 1)\n",
    "#     plt.plot(epochs_range, train_losses, label=f'Fold {fold_idx} - Train')\n",
    "#     plt.plot(epochs_range, val_losses, label=f'Fold {fold_idx} - Val')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Train & Validation Loss Curves')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# for fold_idx, val_aucs in enumerate(all_fold_val_aucs, 1):\n",
    "#     epochs_range = range(1, len(val_aucs) + 1)\n",
    "#     plt.plot(epochs_range, val_aucs, label=f'Fold {fold_idx}')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Val AUC')\n",
    "# plt.title('Validation AUC Curves per Fold')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14525466-dc8f-4211-b2c6-92f7c8e3567b",
   "metadata": {},
   "source": [
    "# health classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38da936a-596f-4887-900a-586ce48cce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# class HealthClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(HealthClassifier, self).__init__()\n",
    "#         self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.sigm = nn.Sigmoid()\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.linear1(x))\n",
    "#         x = self.sigm(self.linear2(x))\n",
    "#         return x\n",
    "\n",
    "# class HealthClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(HealthClassifier, self).__init__()\n",
    "#         self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.linear1(x))\n",
    "#         x = self.linear2(x)  # No sigmoid\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c8107-3876-4187-ba19-18203db5fdf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 512\n",
    "hidden_dim = 128\n",
    "output_dim = 1 \n",
    "learning_rate = 0.00001   \n",
    "num_epochs = 20           \n",
    "BATCH_SIZE = 4            \n",
    "patience = 5              \n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0001, 0.00001],\n",
    "    'batch_size': [4],\n",
    "    'optimizer': ['adam', 'sgd']\n",
    "    # 'optimizer': ['adam']\n",
    "}\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "\n",
    "class HealthClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(HealthClassifier, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.sigm(self.linear2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "all_fold_train_losses = []\n",
    "all_fold_val_losses = []\n",
    "all_fold_val_aucs = []\n",
    "all_fold_test_aucs = []\n",
    "all_fold_best_val_aucs = []\n",
    "all_fold_best_params = []\n",
    "\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting fold {fold+1}/10\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    best_fold_auc = 0.0\n",
    "    best_fold_params = None\n",
    "    best_model_weights_for_fold = None  \n",
    "\n",
    "  \n",
    "    for (lr, bs, opt_name) in param_combinations:\n",
    "        print(f\"\\n  Searching - (LR={lr}, BatchSize={bs}, Optim={opt_name})\")\n",
    "\n",
    "        train_loader = create_data_loader(\n",
    "            all_folds_train_xvectors[fold],\n",
    "            all_folds_yg_train[fold],\n",
    "            all_folds_yh_train[fold],\n",
    "            all_folds_filenames_train[fold],\n",
    "            batch_size=bs, shuffle=True\n",
    "        )\n",
    "        val_loader = create_data_loader(\n",
    "            all_folds_val_xvectors[fold],\n",
    "            all_folds_yg_val[fold],\n",
    "            all_folds_yh_val[fold],\n",
    "            all_folds_filenames_val[fold],\n",
    "            batch_size=bs, shuffle=False\n",
    "        )\n",
    "\n",
    "        \n",
    "        model = HealthClassifier(input_dim, hidden_dim, output_dim).to(device)  \n",
    "        criterion = nn.BCELoss()\n",
    "        if opt_name == 'adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "        \n",
    "        best_val_auc_for_combo = 0.0\n",
    "        best_model_weights_for_combo = None\n",
    "\n",
    "        -\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for x_vectors, _, health_labels, _ in train_loader:\n",
    "                x_vectors = x_vectors.to(device)\n",
    "                health_labels = health_labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_vectors)\n",
    "                loss = criterion(outputs, health_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            \n",
    "            model.eval()\n",
    "            val_preds = []\n",
    "            val_true = []\n",
    "            with torch.no_grad():\n",
    "                for x_vectors, _, health_labels, _ in val_loader:\n",
    "                    x_vectors = x_vectors.to(device)\n",
    "                    health_labels = health_labels.unsqueeze(1).float().to(device)\n",
    "                    outputs = model(x_vectors)\n",
    "                    val_preds.extend(outputs.cpu().numpy())\n",
    "                    val_true.extend(health_labels.cpu().numpy())\n",
    "\n",
    "            val_auc = roc_auc_score(val_true, val_preds)\n",
    "\n",
    "            \n",
    "            if val_auc > best_val_auc_for_combo:\n",
    "                best_val_auc_for_combo = val_auc\n",
    "                best_model_weights_for_combo = copy.deepcopy(model.state_dict())\n",
    "\n",
    "     \n",
    "        if best_val_auc_for_combo > best_fold_auc:\n",
    "            best_fold_auc = best_val_auc_for_combo\n",
    "            best_fold_params = (lr, bs, opt_name)\n",
    "            best_model_weights_for_fold = best_model_weights_for_combo\n",
    "\n",
    " \n",
    "    print(f\"\\nBest hyperparameters for fold {fold+1}:\")\n",
    "    print(f\"   LR={best_fold_params[0]}, BatchSize={best_fold_params[1]}, Optim={best_fold_params[2]}\")\n",
    "    print(f\"   Best Val AUC from grid search = {best_fold_auc:.4f}\")\n",
    "\n",
    "    all_fold_best_params.append(best_fold_params)\n",
    "\n",
    "\n",
    "    final_bs = best_fold_params[1] \n",
    "    final_train_loader = create_data_loader(\n",
    "        all_folds_train_xvectors[fold],\n",
    "        all_folds_yg_train[fold],\n",
    "        all_folds_yh_train[fold],\n",
    "        all_folds_filenames_train[fold],\n",
    "        batch_size=final_bs, shuffle=True\n",
    "    )\n",
    "    final_val_loader = create_data_loader(\n",
    "        all_folds_val_xvectors[fold],\n",
    "        all_folds_yg_val[fold],\n",
    "        all_folds_yh_val[fold],\n",
    "        all_folds_filenames_val[fold],\n",
    "        batch_size=final_bs, shuffle=False\n",
    "    )\n",
    "    test_loader = create_data_loader(\n",
    "        all_folds_test_xvectors[fold],\n",
    "        all_folds_yg_test[fold],\n",
    "        all_folds_yh_test[fold],\n",
    "        all_folds_filenames_test[fold],\n",
    "        batch_size=final_bs, shuffle=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    model_health = HealthClassifier(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "    \n",
    "    if best_fold_params[2] == 'adam':\n",
    "        optimizer_h = optim.Adam(model_health.parameters(), lr=best_fold_params[0]) \n",
    "    else:\n",
    "        optimizer_h = optim.SGD(model_health.parameters(), lr=best_fold_params[0], momentum=0.9)\n",
    "\n",
    "    criterion_h = nn.BCELoss()\n",
    "\n",
    "   \n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_val_aucs = []\n",
    "\n",
    "    best_val_auc_this_fold = 0.0\n",
    "    best_model_weights_this_fold = None\n",
    "    epochs_without_improvement = 0  \n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model_health.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for x_vectors, _, health_labels, _ in final_train_loader:\n",
    "            x_vectors = x_vectors.to(device)\n",
    "            health_labels = health_labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "            optimizer_h.zero_grad()\n",
    "            outputs = model_health(x_vectors)\n",
    "            loss = criterion_h(outputs, health_labels)\n",
    "            loss.backward()\n",
    "            optimizer_h.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        \n",
    "        train_loss = running_loss / len(final_train_loader)\n",
    "        fold_train_losses.append(train_loss)\n",
    "\n",
    "      \n",
    "        model_health.eval()\n",
    "        val_loss_accum = 0.0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_vectors, _, health_labels, _ in final_val_loader:\n",
    "                x_vectors = x_vectors.to(device)\n",
    "                health_labels = health_labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "                outputs = model_health(x_vectors)\n",
    "                val_loss = criterion_h(outputs, health_labels)\n",
    "                val_loss_accum += val_loss.item()\n",
    "\n",
    "                val_preds.extend(outputs.cpu().numpy())\n",
    "                val_true.extend(health_labels.cpu().numpy())\n",
    "\n",
    "        val_loss_avg = val_loss_accum / len(final_val_loader)\n",
    "        val_auc = roc_auc_score(val_true, val_preds)\n",
    "\n",
    "        fold_val_losses.append(val_loss_avg)\n",
    "        fold_val_aucs.append(val_auc)\n",
    "\n",
    "    \n",
    "        if val_auc > best_val_auc_this_fold:\n",
    "            best_val_auc_this_fold = val_auc\n",
    "            best_model_weights_this_fold = copy.deepcopy(model_health.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"  [Early Stopping] No improvement for {patience} epochs. Stopping at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss_avg:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    final_model_path = f\"model_health_fold_{fold+1}_finalNVZ.pth\"\n",
    "    torch.save(model_health.state_dict(), final_model_path)\n",
    "    print(f\"Saved FINAL model for Fold {fold+1} as '{final_model_path}'\")\n",
    "\n",
    "  \n",
    "    if best_model_weights_this_fold is not None:\n",
    "        best_model_path = f\"model_health_fold_{fold+1}_bestValNVZ.pth\"\n",
    "        torch.save(best_model_weights_this_fold, best_model_path)\n",
    "        print(f\"Saved BEST-VAL model for Fold {fold+1} (AUC={best_val_auc_this_fold:.4f}) as '{best_model_path}'\")\n",
    "    else:\n",
    "        print(\"No improvement was tracked, best_model_weights_this_fold is None (check logic).\")\n",
    "\n",
    "\n",
    "    if best_model_weights_this_fold is not None:\n",
    "        model_health.load_state_dict(best_model_weights_this_fold)\n",
    "\n",
    "    model_health.eval()\n",
    "    test_true, test_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_vectors, _, health_labels, _ in test_loader:\n",
    "            x_vectors = x_vectors.to(device)\n",
    "            health_labels = health_labels.unsqueeze(1).float().to(device)\n",
    "            outputs = model_health(x_vectors)\n",
    "\n",
    "            test_preds.extend(outputs.cpu().numpy())\n",
    "            test_true.extend(health_labels.cpu().numpy())\n",
    "\n",
    "    test_auc = roc_auc_score(test_true, test_preds)\n",
    "    all_fold_test_aucs.append(test_auc)\n",
    "    print(f\"\\nFold {fold+1}, Test ROC AUC: {test_auc:.4f}\")\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_true, test_preds)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'Fold {fold+1} (AUC={test_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Health Test ROC - Fold {fold+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    all_fold_train_losses.append(fold_train_losses)\n",
    "    all_fold_val_losses.append(fold_val_losses)\n",
    "    all_fold_val_aucs.append(fold_val_aucs)\n",
    "    all_fold_best_val_aucs.append(best_val_auc_this_fold)\n",
    "\n",
    "\n",
    "avg_test_auc = np.mean(all_fold_test_aucs)\n",
    "std_test_auc = np.std(all_fold_test_aucs, ddof=1)\n",
    "print(f\"\\nAverage Test ROC AUC: {avg_test_auc:.4f} ± {std_test_auc:.4f}\")\n",
    "\n",
    "avg_best_val_auc = np.mean(all_fold_best_val_aucs)\n",
    "std_best_val_auc = np.std(all_fold_best_val_aucs, ddof=1)\n",
    "print(f\"Average BEST Val AUC Across Folds: {avg_best_val_auc:.4f} ± {std_best_val_auc:.4f}\")\n",
    "\n",
    "print(\"\\nBest Parameters per Fold:\")\n",
    "for fold_idx, params in enumerate(all_fold_best_params):\n",
    "    print(f\"  Fold {fold_idx+1}: LR={params[0]}, BS={params[1]}, Optim={params[2]}\")\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# for fold_idx, (train_losses, val_losses) in enumerate(zip(all_fold_train_losses, all_fold_val_losses), 1):\n",
    "#     # Each fold might have a different number of epochs if early stopping triggered\n",
    "#     epochs_range = range(1, len(train_losses) + 1)\n",
    "#     plt.plot(epochs_range, train_losses, label=f'Fold {fold_idx} - Train')\n",
    "#     plt.plot(epochs_range, val_losses, label=f'Fold {fold_idx} - Val')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Train & Validation Loss Curves')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# for fold_idx, val_aucs in enumerate(all_fold_val_aucs, 1):\n",
    "#     epochs_range = range(1, len(val_aucs) + 1)\n",
    "#     plt.plot(epochs_range, val_aucs, label=f'Fold {fold_idx}')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Val AUC')\n",
    "# plt.title('Validation AUC Curves per Fold')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bf680-26f5-4051-92b9-92be6030b4be",
   "metadata": {},
   "source": [
    "# Gradient Reversal Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "407e07bb-f56f-43c4-b0c7-e2db4e80c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "class GradReverse(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg()\n",
    "\n",
    "def grad_reverse(x):\n",
    "    return GradReverse.apply(x)\n",
    "\n",
    "\n",
    "class Discrim(nn.Module):                                                 \n",
    "    def __init__(self,input_dim,hidden_dim):\n",
    "        super(Discrim, self).__init__()\n",
    "        self.input_dim  = input_dim\n",
    "        self.linear1 = torch.nn.Linear(input_dim,1)\n",
    "        # self.linear2 = torch.nn.Linear(hidden_dim,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        att_pred = self.linear1(x)\n",
    "        # att_pred = F.relu(att_pred)\n",
    "        # att_pred = self.linear2(att_pred)\n",
    "        att_pred = torch.sigmoid(att_pred)\n",
    "        return att_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.linear1 = torch.nn.Linear(input_dim, latent_dim)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.linear2 = torch.nn.Linear(latent_dim, input_dim)\n",
    "        self.discriminator = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x / torch.norm(x, dim=1, keepdim=True)  \n",
    "        z = F.relu(self.linear1(x))\n",
    "        z = self.bn1(z)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = torch.tanh(self.linear2(z))\n",
    "        x = x / torch.norm(x, dim=1, keepdim=True)  \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        rev_z = grad_reverse(z)\n",
    "        att_pred = self.discriminator(rev_z)  \n",
    "        outputs = self.decode(z)\n",
    "        return outputs, z, att_pred\n",
    "\n",
    "\n",
    "def recons_loss_function(out_x, x):\n",
    "    recons_loss = torch.mean(1-F.cosine_similarity(out_x, x.view(-1,INPUT_SIZE),dim=1))\n",
    "    return recons_loss\n",
    "\n",
    "\n",
    "def discrim_loss_function(pred, lbl):\n",
    "    bce_loss        = torch.nn.BCELoss()\n",
    "    discrim_loss    = bce_loss(pred, lbl)\n",
    "    return discrim_loss\n",
    "\n",
    "\n",
    "# diagnosis_loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "INPUT_SIZE      = 512   \n",
    "input_dim  = 512\n",
    "latent_dim = 128\n",
    "input_dim_discrim  = latent_dim\n",
    "hidden_dim_discrim = 128\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# model_ae  = Autoencoder(input_dim, latent_dim)\n",
    "# optimizer_ae  = torch.optim.SGD(model_ae.parameters(), lr = 0.0001, momentum=0.9)\n",
    "# model_ae.to(device)\n",
    "\n",
    "# model_discrim   = Discrim(input_dim_discrim, hidden_dim_discrim)\n",
    "# optimizer_discrim   = torch.optim.SGD(model_discrim.parameters(), lr = 0.0001, momentum=0.9)\n",
    "# model_discrim.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# output_dim_health = 1  \n",
    "\n",
    "# modelD = HealthClass(latent_dim, output_dim_health).to(device)\n",
    "# optimizer_modelD = optim.Adam(modelD.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a20090-a98f-4660-b601-647e44bd2e03",
   "metadata": {},
   "source": [
    "# Adversarial Disentanglement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a4349-a50f-4645-b947-ab06a69eb87f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_folds_roc_curves = []\n",
    "all_fold_auc_scores = []\n",
    "\n",
    "\n",
    "\n",
    "all_fold_accuracies = []\n",
    "all_fold_f1_scores = []\n",
    "all_fold_recalls = []\n",
    "all_fold_precisions = []\n",
    "\n",
    "\n",
    "all_fold_val_auc_scores = []\n",
    "all_fold_val_accuracies = []\n",
    "all_fold_val_f1_scores = [] \n",
    "all_fold_val_recalls = []\n",
    "all_fold_val_precisions = []\n",
    "\n",
    "\n",
    "####for health classifier validation\n",
    "\n",
    "all_fold_val_health_auc_scores = []\n",
    "all_fold_val_health_accuracies = []\n",
    "all_fold_val_health_f1_scores = []\n",
    "all_fold_val_health_recalls = []\n",
    "all_fold_val_health_precisions = []\n",
    "\n",
    "\n",
    "####for health classifier test\n",
    "all_fold_health_auc_scores = []\n",
    "all_folds_health_roc_curves = []\n",
    "all_fold_health_accuracies = []\n",
    "all_fold_health_f1_scores = []\n",
    "all_fold_health_recalls = []\n",
    "all_fold_health_precisions = []\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0001],\n",
    "    'batch_size': [4],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'lmda': [0.1, 0.9, 1, 2]\n",
    "}\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(10):\n",
    "    print(f\"\\nStarting training for fold {fold + 1}/10\")\n",
    "\n",
    "    best_val_auc = 0.0\n",
    "    best_params = None\n",
    "    best_model_ae_state = None\n",
    "\n",
    "    for (lr, bs, opt_name, lmda) in param_combinations:\n",
    "        print(f\"\\n  Searching - (LR={lr}, BatchSize={bs}, Optim={opt_name}, Lambda={lmda}))\")\n",
    "    \n",
    "        \n",
    "        \n",
    "        train_loader = create_data_loader(\n",
    "            all_folds_train_xvectors[fold], all_folds_yg_train[fold], all_folds_yh_train[fold],\n",
    "            all_folds_filenames_train[fold], bs, shuffle=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "        val_loader = create_data_loader(\n",
    "            all_folds_val_xvectors[fold], all_folds_yg_val[fold], all_folds_yh_val[fold],\n",
    "            all_folds_filenames_val[fold],\n",
    "            bs, shuffle=False\n",
    "        )    \n",
    "    \n",
    "    \n",
    "        test_loader = create_data_loader(\n",
    "            all_folds_test_xvectors[fold], all_folds_yg_test[fold], all_folds_yh_test[fold],\n",
    "            all_folds_filenames_test[fold], bs, shuffle=False\n",
    "        )\n",
    "\n",
    "        \n",
    "        model_ae  = Autoencoder(input_dim, latent_dim)\n",
    "        # optimizer_ae  = torch.optim.SGD(model_ae.parameters(), lr = 0.001, momentum=0.9)\n",
    "        # optimizer_ae  = optim.Adam(model_ae.parameters(), lr=0.001)\n",
    "        \n",
    "        if opt_name == 'adam':\n",
    "            optimizer_ae = optim.Adam(model_ae.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer_ae = optim.SGD(model_ae.parameters(), lr=lr, momentum=0.9)\n",
    "        \n",
    "        model_ae.to(device)\n",
    "        \n",
    "        # model_discrim   = Discrim(input_dim_discrim, hidden_dim_discrim)\n",
    "        # optimizer_discrim   = torch.optim.SGD(model_discrim.parameters(), lr = 0.0001, momentum=0.9)\n",
    "        # model_discrim.to(device)\n",
    "        \n",
    "        # Training loop for the current fold\n",
    "        for epoch in range(EPOCHS):\n",
    "            model_ae.train()\n",
    "            running_loss = 0.0\n",
    "            running_recons_loss = 0.0\n",
    "            running_ad_loss = 0.0\n",
    "            running_discrim_loss = 0.0\n",
    "            # running_diagnosis_loss = 0.0\n",
    "            num_batches = 0\n",
    "    \n",
    "            print(f\"_____FOLD {fold + 1} - EPOCH: {epoch + 1}/{EPOCHS}_____\")\n",
    "            for x_vectors, gender_labels, health_labels, filenames in train_loader:\n",
    "                local_batch = x_vectors.to(device)\n",
    "                local_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "                \n",
    "    \n",
    "                optimizer_ae.zero_grad()\n",
    "                # optimizer_discrim.zero_grad()\n",
    "    \n",
    "                \n",
    "                outputs, z, att_pred = model_ae(local_batch)\n",
    "    \n",
    "              \n",
    "                loss_discrim = discrim_loss_function(att_pred, local_labels)\n",
    "                # loss_discrim.backward(retain_graph=True)\n",
    "                # optimizer_discrim.step()\n",
    "    \n",
    "    \n",
    "                # outputs, z, att_pred = model_ae(local_batch)\n",
    "    \n",
    "                # Adversarial loss\n",
    "                # ad_loss = discrim_loss_function(att_pred, local_labels)\n",
    "    \n",
    "                \n",
    "                recons_loss = recons_loss_function(outputs, local_batch)\n",
    "    \n",
    "                # Total loss\n",
    "                loss = recons_loss + loss_discrim*lmda\n",
    "                loss.backward()\n",
    "                # optimizer_discrim.step()\n",
    "                optimizer_ae.step()\n",
    "    \n",
    "                # Accumulate losses\n",
    "                running_loss += loss.item()\n",
    "                running_recons_loss += recons_loss.item()\n",
    "                # running_ad_loss += ad_loss.item()\n",
    "                running_discrim_loss += loss_discrim.item()\n",
    "                # running_diagnosis_loss += diagnosis_loss.item()\n",
    "                num_batches += 1\n",
    "    \n",
    "            h\n",
    "            print(\"..............\")\n",
    "            print(f\"Training Loss: {running_loss / num_batches:.4f}\")\n",
    "            print(f\"Reconstruction Loss: {running_recons_loss / num_batches:.4f}\")\n",
    "            # print(f\"Adversarial Loss: {running_ad_loss / num_batches:.4f}\")\n",
    "            print(f\"Discriminator Loss: {running_discrim_loss / num_batches:.4f}\")\n",
    "            # print(f\"Diagnosis Loss: {running_diagnosis_loss / num_batches:.4f}\")\n",
    "    \n",
    "    \n",
    "           \n",
    "        \n",
    "        model_ae.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_recons_loss = 0.0\n",
    "        val_running_discrim_loss = 0.0\n",
    "        val_num_batches = 0\n",
    "    \n",
    "        val_true_labels = []\n",
    "        val_probs = []\n",
    "    \n",
    "        print(f\"_____(Validation)_____\")\n",
    "        with torch.no_grad():\n",
    "            for x_vectors, gender_labels, health_labels, filenames in val_loader:\n",
    "                local_batch = x_vectors.to(device)\n",
    "                local_labels = gender_labels.unsqueeze(1).float().to(device)\n",
    "                    \n",
    "                outputs, z, att_pred = model_ae(local_batch)\n",
    "                    \n",
    "                val_loss_discrim = discrim_loss_function(att_pred, local_labels)\n",
    "                val_recons_loss = recons_loss_function(outputs, local_batch)\n",
    "                val_loss_total = val_recons_loss + val_loss_discrim\n",
    "          \n",
    "                val_running_loss += val_loss_total.item()\n",
    "                val_running_recons_loss += val_recons_loss.item()\n",
    "                val_running_discrim_loss += val_loss_discrim.item()\n",
    "                val_num_batches += 1\n",
    "                    \n",
    "                val_probs.extend(att_pred.cpu().numpy().flatten())\n",
    "                val_true_labels.extend(local_labels.cpu().numpy().flatten())\n",
    "    \n",
    "        if val_num_batches > 0:\n",
    "            avg_val_loss = val_running_loss / val_num_batches\n",
    "            avg_val_recons = val_running_recons_loss / val_num_batches\n",
    "            avg_val_discrim = val_running_discrim_loss / val_num_batches\n",
    "        else:\n",
    "            avg_val_loss = 0.0\n",
    "            avg_val_recons = 0.0\n",
    "            avg_val_discrim = 0.0\n",
    "    \n",
    "          \n",
    "    \n",
    "        threshold = 0.5\n",
    "        val_pred_labels = [1 if prob >= threshold else 0 for prob in val_probs]\n",
    "        \n",
    "        # val_accuracy = accuracy_score(val_true_labels, val_pred_labels)\n",
    "        # val_f1 = f1_score(val_true_labels, val_pred_labels)\n",
    "        # val_recall = recall_score(val_true_labels, val_pred_labels)\n",
    "        # val_precision = precision_score(val_true_labels, val_pred_labels)\n",
    "        val_auc = roc_auc_score(val_true_labels, val_probs)\n",
    "    \n",
    "        # all_fold_val_accuracies.append(val_accuracy)\n",
    "        # all_fold_val_f1_scores.append(val_f1)\n",
    "        # all_fold_val_recalls.append(val_recall)\n",
    "        # all_fold_val_precisions.append(val_precision)\n",
    "        all_fold_val_auc_scores.append(val_auc)\n",
    "        \n",
    "        # print(f\"Validation - Fold {fold+1}, Epoch {epoch+1}/{EPOCHS}\")\n",
    "        # print(f\"  Loss: {avg_val_loss:.4f} | Recons: {avg_val_recons:.4f} | Discrim: {avg_val_discrim:.4f}\")\n",
    "        # print(f\"  Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}, Recall: {val_recall:.4f}, Precision: {val_precision:.4f}, AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # torch.save(model_ae.state_dict(), f\"model_ae_fold_{fold + 1}NVZ.pth\")\n",
    "\n",
    "        \n",
    "        model_health = HealthClassifier(input_dim, hidden_dim, output_dim).to(device)\n",
    "        model_health.load_state_dict(torch.load(f\"model_health_fold_{fold+1}_bestValNVZ.pth\"))\n",
    "        model_health.eval()\n",
    "        \n",
    "        model_ae.eval()\n",
    "        val_health_probs = []\n",
    "        val_health_labels = []\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for x_vectors, _, health_labels, _ in val_loader:\n",
    "                local_batch = x_vectors.to(device)\n",
    "                local_health_labels = health_labels.view(-1, 1).float().to(device)\n",
    "            \n",
    "                outputs, _, _ = model_ae(local_batch)\n",
    "                val_health_pred = model_health(outputs)\n",
    "            \n",
    "                val_health_probs.extend(val_health_pred.cpu().numpy().flatten())\n",
    "                val_health_labels.extend(local_health_labels.cpu().numpy().flatten())\n",
    "            \n",
    "        val_health_probs = np.array(val_health_probs)\n",
    "        val_health_labels = np.array(val_health_labels)\n",
    "        threshold = 0.5\n",
    "        val_health_pred_labels = (val_health_probs >= threshold).astype(int)\n",
    "            \n",
    "        # val_health_accuracy = accuracy_score(val_health_labels, val_health_pred_labels)\n",
    "        # val_health_f1       = f1_score(val_health_labels, val_health_pred_labels)\n",
    "        # val_health_recall   = recall_score(val_health_labels, val_health_pred_labels)\n",
    "        # val_health_precision= precision_score(val_health_labels, val_health_pred_labels)\n",
    "        val_health_auc      = roc_auc_score(val_health_labels, val_health_probs)\n",
    "            \n",
    "        # all_fold_val_health_accuracies.append(val_health_accuracy)\n",
    "        # all_fold_val_health_f1_scores.append(val_health_f1)\n",
    "        # all_fold_val_health_recalls.append(val_health_recall)\n",
    "        # all_fold_val_health_precisions.append(val_health_precision)\n",
    "        all_fold_val_health_auc_scores.append(val_health_auc)\n",
    "            \n",
    "        # print(f\"Fold {fold + 1} - Health (VAL) Metrics:\")\n",
    "        # print(f\"  Accuracy_health: {val_health_accuracy:.4f}\")\n",
    "        # print(f\"  F1_health:       {val_health_f1:.4f}\")\n",
    "        # print(f\"  Recall_health:   {val_health_recall:.4f}\")\n",
    "        # print(f\"  Precision_health:{val_health_precision:.4f}\")\n",
    "        # print(f\"  AUC_health:      {val_health_auc:.4f}\")\n",
    "        if 0.45 <= val_auc <= 0.55:\n",
    "            if val_health_auc > best_val_auc:\n",
    "                best_val_auc = val_health_auc\n",
    "                best_params = (lr, bs, opt_name, lmda)\n",
    "                best_model_ae_state = copy.deepcopy(model_ae.state_dict())\n",
    "        \n",
    "\n",
    "    if best_params is not None:\n",
    "        print(f\"\\nBest hyperparameters found: LR={best_params[0]}, BS={best_params[1]}, Optim={best_params[2]}, Lambda={best_params[3]}\")\n",
    "        print(f\"Best validation AUC for health classifier: {best_val_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo optimal parameters found for this fold.\")\n",
    "        \n",
    "    # print(f\"\\nBest hyperparameters found: LR={best_params[0]}, BS={best_params[1]}, Optim={best_params[2]}, Lambda={best_params[3]}\")\n",
    "    # print(f\"Best validation AUC for health classifier: {best_val_auc:.4f}\")\n",
    "        \n",
    "            \n",
    "    torch.save(best_model_ae_state, f\"best_ae_for_health_fold_{fold+1}.pth\")\n",
    "           \n",
    "        # model_discrim.eval()  # Switch discriminator to evaluation mode\n",
    "\n",
    "    print(f\"\\nEvaluating Gender Prediction for Fold {fold + 1}/5\")\n",
    "    \n",
    "    model_gender = GenderClassifier(input_dim, output_dim).to(device)\n",
    "    model_gender.load_state_dict(torch.load(f\"model_gender_fold_{fold+1}_bestValNVZ.pth\"))\n",
    "    model_gender.eval()\n",
    "\n",
    "    best_ae_for_fold = Autoencoder(input_dim, latent_dim).to(device)\n",
    "    best_ae_for_fold.load_state_dict(torch.load(f\"best_ae_for_health_fold_{fold+1}.pth\"))\n",
    "    best_ae_for_fold.eval()\n",
    "        \n",
    "    true_labels, att_probs = [], []\n",
    "        \n",
    "    with torch.no_grad(): \n",
    "        for x_vectors, gender_labels, _, _ in test_loader:\n",
    "            local_batch, local_labels = x_vectors.to(device), gender_labels.view(-1, 1).float().to(device)\n",
    "        \n",
    "            outputs, z, att_pred = best_ae_for_fold(local_batch) \n",
    "            gender_pred = model_gender(outputs)\n",
    "            att_probs.extend(gender_pred.cpu().numpy().flatten())\n",
    "            true_labels.extend(local_labels.cpu().numpy().flatten())\n",
    "    \n",
    "    \n",
    "    threshold = 0.5\n",
    "    pred_labels = [1 if prob >= threshold else 0 for prob in att_probs]\n",
    "    \n",
    "        \n",
    "    # accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    # f1 = f1_score(true_labels, pred_labels)\n",
    "    # recall = recall_score(true_labels, pred_labels)\n",
    "    # precision = precision_score(true_labels, pred_labels)\n",
    "        \n",
    "    # all_fold_accuracies.append(accuracy)\n",
    "    # all_fold_f1_scores.append(f1)\n",
    "    # all_fold_recalls.append(recall)\n",
    "    # all_fold_precisions.append(precision)\n",
    "    \n",
    "    # print(f\"Fold {fold + 1}:\")\n",
    "        \n",
    "    # print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"  F1 Score: {f1:.4f}\")\n",
    "    # print(f\"  Recall: {recall:.4f}\")\n",
    "    # print(f\"  Precision: {precision:.4f}\\n\")\n",
    "        \n",
    "            \n",
    "    auc_score = roc_auc_score(true_labels, att_probs)\n",
    "    all_fold_auc_scores.append(auc_score)\n",
    "    print(f\"Fold {fold + 1} - AUC Score: {auc_score:.4f}\")\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(true_labels, att_probs)\n",
    "    all_folds_roc_curves.append((fpr, tpr))\n",
    "    \n",
    "        \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.plot(fpr, tpr, label=f'Fold {fold + 1} ROC curve (AUC = {auc_score:.4f})', color='darkorange', lw=2)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--', lw=2)  # Diagonal line for random guessing\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve for Fold {fold + 1}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nEvaluating Health Prediction for Fold {fold + 1}/10\")\n",
    "    \n",
    "    model_health = HealthClassifier(input_dim, hidden_dim, output_dim).to(device)\n",
    "    model_health.load_state_dict(torch.load(f\"model_health_fold_{fold+1}_bestValNVZ.pth\"))\n",
    "    model_health.eval()\n",
    "\n",
    "    best_ae_for_fold = Autoencoder(input_dim, latent_dim).to(device)\n",
    "    best_ae_for_fold.load_state_dict(torch.load(f\"best_ae_for_health_fold_{fold+1}.pth\"))\n",
    "    best_ae_for_fold.eval()\n",
    "\n",
    "    all_health_probs = []\n",
    "    all_health_labels = []    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_vectors, _, health_labels, _ in test_loader:\n",
    "            local_batch, local_health_labels = x_vectors.to(device), health_labels.view(-1, 1).float().to(device)\n",
    "\n",
    "            \n",
    "            outputs, _, _ = best_ae_for_fold(local_batch)\n",
    "\n",
    "            \n",
    "            health_pred = model_health(outputs)\n",
    "\n",
    "            \n",
    "            all_health_probs.extend(health_pred.cpu().numpy().flatten())\n",
    "            all_health_labels.extend(local_health_labels.cpu().numpy().flatten())\n",
    "\n",
    "    \n",
    "    all_health_probs = np.array(all_health_probs)\n",
    "    all_health_labels = np.array(all_health_labels)\n",
    "\n",
    "    threshold = 0.5\n",
    "    pred_labels = (all_health_probs >= threshold).astype(int)\n",
    "\n",
    "    # accuracy = accuracy_score(all_health_labels, pred_labels)\n",
    "    # f1 = f1_score(all_health_labels, pred_labels)\n",
    "    # recall = recall_score(all_health_labels, pred_labels)\n",
    "    # precision = precision_score(all_health_labels, pred_labels)\n",
    "\n",
    "    # all_fold_health_accuracies.append(accuracy)\n",
    "    # all_fold_health_f1_scores.append(f1)\n",
    "    # all_fold_health_recalls.append(recall)\n",
    "    # all_fold_health_precisions.append(precision)\n",
    "\n",
    "    # print(f\"Fold {fold + 1} - Health Metrics:\")\n",
    "    \n",
    "    # print(f\"  Accuracy_health: {accuracy:.4f}\")\n",
    "    # print(f\"  F1 Score_health: {f1:.4f}\")\n",
    "    # print(f\"  Recall_health: {recall:.4f}\")\n",
    "    # print(f\"  Precision_health: {precision:.4f}\")\n",
    "\n",
    "    auc_score = roc_auc_score(all_health_labels, all_health_probs)\n",
    "    all_fold_health_auc_scores.append(auc_score)\n",
    "    print(f\"Fold {fold + 1} - Health AUC: {auc_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean_val_auc  = np.mean(all_fold_val_auc_scores)\n",
    "std_val_auc   = np.std(all_fold_val_auc_scores)\n",
    "\n",
    "mean_val_acc  = np.mean(all_fold_val_accuracies)\n",
    "std_val_acc   = np.std(all_fold_val_accuracies)\n",
    "\n",
    "mean_auc = np.mean(all_fold_auc_scores)\n",
    "std_auc = np.std(all_fold_auc_scores)\n",
    "\n",
    "print(\"\\n AVERAGE VALIDATION METRICS ACROSS FOLDS (validation)\")\n",
    "print(f\"Val AUC:        {mean_val_auc:.4f} ± {std_val_auc:.4f}\")\n",
    "print(f\"Val Accuracy:   {mean_val_acc:.4f} ± {std_val_acc:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nMean AUC across folds(TEST): {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "\n",
    "# mean_accuracy = np.mean(all_fold_accuracies)\n",
    "# std_accuracy = np.std(all_fold_accuracies)\n",
    "# mean_f1 = np.mean(all_fold_f1_scores)\n",
    "# std_f1 = np.std(all_fold_f1_scores)\n",
    "# mean_recall = np.mean(all_fold_recalls)\n",
    "# std_recall = np.std(all_fold_recalls)\n",
    "# mean_precision = np.mean(all_fold_precisions)\n",
    "# std_precision = np.std(all_fold_precisions)\n",
    "\n",
    "\n",
    "# print(f\"  Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "# print(f\"  F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "# print(f\"  Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "# print(f\"  Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr in all_folds_roc_curves], axis=0)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(mean_fpr, mean_tpr, label=f'Mean ROC Curve (AUC = {mean_auc:.4f})', color='blue', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', lw=2)  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Mean ROC Curve Across All Folds')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show() \n",
    "\n",
    "\n",
    "mean_health_auc = np.mean(all_fold_health_auc_scores)\n",
    "std_health_auc = np.std(all_fold_health_auc_scores)\n",
    "\n",
    "# mean_health_accuracy = np.mean(all_fold_health_accuracies)\n",
    "# std_health_accuracy = np.std(all_fold_health_accuracies)\n",
    "# mean_health_f1 = np.mean(all_fold_health_f1_scores)\n",
    "# std_health_f1 = np.std(all_fold_health_f1_scores)\n",
    "# mean_health_recall = np.mean(all_fold_health_recalls)\n",
    "# std_health_recall = np.std(all_fold_health_recalls)\n",
    "# mean_health_precision = np.mean(all_fold_health_precisions)\n",
    "# std_health_precision = np.std(all_fold_health_precisions)\n",
    "\n",
    "\n",
    "# print(f\"  Accuracy_health: {mean_health_accuracy:.4f} ± {std_health_accuracy:.4f}\")\n",
    "# print(f\"  F1 Score_health: {mean_health_f1:.4f} ± {std_health_f1:.4f}\")\n",
    "# print(f\"  Recall_health: {mean_health_recall:.4f} ± {std_health_recall:.4f}\")\n",
    "# print(f\"  Precision_health: {mean_health_precision:.4f} ± {std_health_precision:.4f}\")\n",
    "\n",
    "print(f\"\\nMean Health AUC across folds: {mean_health_auc:.4f} ± {std_health_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
